{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4e3062eee800d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T22:53:59.012435Z",
     "start_time": "2025-03-19T22:53:57.440237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04987ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n",
      "C:\\Users\\Konstantin-Asen\\AppData\\Local\\Temp\\ipykernel_9736\\2313528923.py:8: DeprecationWarning: Call to deprecated method pt.init(). Deprecated since version 0.11.0.\n",
      "java is now started automatically with default settings. To force initialisation early, run:\n",
      "pt.java.init() # optional, forces java initialisation\n",
      "  pt.init()\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "from itertools import filterfalse\n",
    "import os\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65070aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Konstantin-Asen\\Desktop\\IR-research-project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyterrier_colbert.indexing import ColBERTIndexer\n",
    "from pyterrier_colbert.ranking import ColBERTFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c06473b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ance.pyterrier_ance import ANCEIndexer, ANCETextScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a1c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaswani = pt.get_dataset(\"irds:vaswani\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be47023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:45:35.890 [main] WARN org.terrier.structures.FSADocumentIndex -- This index has fields, but FSADocumentIndex is used (which stores fields lengths on disk); If using field-based models such as BM25F, change to index.document.class in the index  properties file to FSAFieldDocumentIndex or FSADocumentIndexInMemFields to support efficient retrieval. If you don't use (e.g.) BM25F, this warning can be ignored\n"
     ]
    }
   ],
   "source": [
    "vaswani_index_src = os.path.abspath(\"vaswani-index\")\n",
    "if not os.path.exists(vaswani_index_src):\n",
    "    print(\"Creating a new Vaswani index for BM25 and RM3...\")\n",
    "    pt.index.IterDictIndexer(vaswani_index_src, blocks=True, meta={\"docno\": 20, \"text\": 4096}).index(vaswani.get_corpus_iter(), fields=[\"docno\", \"text\"])\n",
    "\n",
    "vaswani_index = pt.IndexFactory.of(vaswani_index_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df91db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = vaswani.get_topics()\n",
    "qrels = vaswani.get_qrels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce86e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = pt.terrier.Retriever(vaswani_index, wmodel=\"BM25\", metadata=[\"docno\", \"text\"])\n",
    "rm3 = pt.rewrite.RM3(vaswani_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80da348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_url = \"http://www.dcs.gla.ac.uk/~craigm/colbert.dnn.zip\"\n",
    "extract_dir = \"colbert_checkpoint\"\n",
    "checkpoint_path = \"colbert_checkpoint.zip\"\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(\"Downloading checkpoint...\")\n",
    "    wget.download(checkpoint_url, checkpoint_path)\n",
    "if not os.path.exists(extract_dir):\n",
    "    with zipfile.ZipFile(checkpoint_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "colbert_checkpoint_path = os.path.abspath(\"colbert_checkpoint/colbert.dnn\")\n",
    "index_root = os.path.abspath(\"vaswani-index\")\n",
    "index_name = os.path.abspath(\"vaswani-colbert-index\")\n",
    "\n",
    "if not os.path.exists(index_name):\n",
    "    print(\"Index not found. Creating a new Vaswani index for ColBERT...\")\n",
    "    colbert_index = ColBERTIndexer(\n",
    "        checkpoint=colbert_checkpoint_path,\n",
    "        index_root=index_root,\n",
    "        index_name=index_name,\n",
    "        chunksize=64, # Maybe even 128, the allowed maximum --> it regulates the size of PyTorch temp files that are created by the indexer\n",
    "        gpu=True # if the torch.cuda returned False, comment this\n",
    "    )\n",
    "    colbert_index.index(vaswani.get_corpus_iter())\n",
    "    print(\"Index successfully created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d02e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 26, 21:45:38] #> Loading model checkpoint.\n",
      "[Mar 26, 21:45:38] #> Loading checkpoint c:\\Users\\Konstantin-Asen\\Desktop\\IR-research-project\\colbert_checkpoint\\colbert.dnn\n",
      "[Mar 26, 21:45:39] #> checkpoint['epoch'] = 0\n",
      "[Mar 26, 21:45:39] #> checkpoint['batch'] = 44500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Konstantin-Asen\\Desktop\\IR-research-project\\.venv\\Lib\\site-packages\\colbert\\utils\\amp.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "colbert_reranker = ColBERTFactory(colbert_checkpoint_path, index_root, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a080b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ance_extract_dir = \"ance_checkpoint\"\n",
    "ance_checkpoint_path = \"ance_checkpoint.zip\"\n",
    "\n",
    "if not os.path.exists(ance_extract_dir):\n",
    "    with zipfile.ZipFile(ance_checkpoint_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(ance_extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b676c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ance_checkpoint_path = os.path.abspath(\"ance_checkpoint\")\n",
    "ance_index_name = os.path.abspath(\"vaswani-ance-index\")\n",
    "\n",
    "if not os.path.exists(ance_index_name):\n",
    "    print(\"Index not found. Creating a new Vaswani index for ANCE...\")\n",
    "    ance_index = ANCEIndexer(ance_checkpoint_path, ance_index_name, num_docs=11429)\n",
    "    ance_index.index(vaswani.get_corpus_iter())\n",
    "    print(\"Index successfully created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "626994b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mean: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at c:\\Users\\Konstantin-Asen\\Desktop\\IR-research-project\\ance_checkpoint were not used when initializing RobertaDot_NLL_LN: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaDot_NLL_LN from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaDot_NLL_LN from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ance_reranker = ANCETextScorer(ance_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d6ad7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dict = {\n",
    "    \"BM25\": bm25,\n",
    "    \"BM25_RM3\": bm25 >> rm3 >> bm25,\n",
    "    \"BM25_COLBERT\": bm25 >> colbert_reranker.text_scorer(),\n",
    "    \"BM25_ANCE\": bm25 >> ance_reranker,\n",
    "    \"BM25_RM3_COLBERT\": bm25 >> rm3 >> bm25 >> colbert_reranker.text_scorer(),\n",
    "    \"BM25_RM3_ANCE\": bm25 >> rm3 >> bm25 >> ance_reranker,\n",
    "    \"BM25_COLBERT_RM3\": bm25 >> colbert_reranker.text_scorer() >> rm3 >> bm25,\n",
    "    \"BM25_COLBERT_ANCE\": bm25 >> colbert_reranker.text_scorer() >> pt.text.get_text(vaswani_index) >> ance_reranker,\n",
    "    \"BM25_ANCE_RM3\": bm25 >> ance_reranker >> rm3 >> bm25,\n",
    "    \"BM25_ANCE_COLBERT\": bm25 >> ance_reranker >> colbert_reranker.text_scorer(),\n",
    "    \"BM25_RM3_COLBERT_ANCE\": bm25 >> rm3 >> bm25 >> colbert_reranker.text_scorer() >> pt.text.get_text(vaswani_index) >> ance_reranker,\n",
    "    \"BM25_RM3_ANCE_COLBERT\": bm25 >> rm3 >> bm25 >> ance_reranker >> colbert_reranker.text_scorer(),\n",
    "    \"BM25_COLBERT_RM3_ANCE\": bm25 >> colbert_reranker.text_scorer() >> rm3 >> bm25 >> ance_reranker,\n",
    "    \"BM25_COLBERT_ANCE_RM3\": bm25 >> colbert_reranker.text_scorer() >> pt.text.get_text(vaswani_index) >> ance_reranker >> rm3 >> bm25,\n",
    "    \"BM25_ANCE_RM3_COLBERT\": bm25 >> ance_reranker >> rm3 >> bm25 >> colbert_reranker.text_scorer(),\n",
    "    \"BM25_ANCE_COLBERT_RM3\": bm25 >> ance_reranker >> colbert_reranker.text_scorer() >> rm3 >> bm25\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03337c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ran for 166 minutes\n",
    "\n",
    "if not os.path.exists(\"vaswani-twofold/results.csv\"):\n",
    "    twofold_results = pt.Experiment(\n",
    "        [\n",
    "            bm25,\n",
    "            bm25 >> rm3 >> bm25,\n",
    "            bm25 >> colbert_reranker.text_scorer(),\n",
    "            bm25 >> ance_reranker\n",
    "        ],\n",
    "        queries,\n",
    "        qrels,\n",
    "        [\"map\", \"ndcg_cut_10\", \"recip_rank\", \"mrt\"],\n",
    "        [\"BM25\", \"BM25_RM3\", \"BM25_COLBERT\", \"BM25_ANCE\"],\n",
    "        save_dir=\"vaswani-twofold\",\n",
    "        save_mode=\"reuse\",\n",
    "        baseline=0,\n",
    "        correction=\"bonferroni\"\n",
    "    )\n",
    "    twofold_results.to_csv(\"vaswani-twofold/results.csv\", sep=',', na_rep=\"NaN\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fac6c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Konstantin-Asen\\Desktop\\IR-research-project\\.venv\\Lib\\site-packages\\colbert\\utils\\amp.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else nullcontext()\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Inferencing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:01,  1.04s/it]\n",
      "Inferencing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 727it [23:51,  1.97s/it]\n",
      "Inferencing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:00,  1.09it/s]\n",
      "Inferencing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 719it [23:34,  1.97s/it]\n",
      "c:\\Users\\Konstantin-Asen\\Desktop\\IR-research-project\\.venv\\Lib\\site-packages\\colbert\\utils\\amp.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else nullcontext()\n"
     ]
    }
   ],
   "source": [
    "# Ran for 335 minutes\n",
    "\n",
    "if not os.path.exists(\"vaswani-threefold/results.csv\"):\n",
    "    bm25_rm3 = pt.Transformer.from_df(pt.io.read_results(\"vaswani-twofold/BM25_RM3.res.gz\"), uniform=False)\n",
    "    bm25_colbert = pt.Transformer.from_df(pt.io.read_results(\"vaswani-twofold/BM25_COLBERT.res.gz\"), uniform=False)\n",
    "    bm25_ance = pt.Transformer.from_df(pt.io.read_results(\"vaswani-twofold/BM25_ANCE.res.gz\"), uniform=False)\n",
    "\n",
    "    threefold_results = pt.Experiment(\n",
    "        [\n",
    "            bm25,\n",
    "            bm25_rm3 >> pt.text.get_text(vaswani_index) >> colbert_reranker.text_scorer(),\n",
    "            bm25_rm3 >> pt.text.get_text(vaswani_index) >> ance_reranker,\n",
    "            bm25_colbert >> rm3 >> bm25,\n",
    "            bm25_colbert >> pt.text.get_text(vaswani_index) >> ance_reranker,\n",
    "            bm25_ance >> rm3 >> bm25,\n",
    "            bm25_ance >> pt.text.get_text(vaswani_index) >> colbert_reranker.text_scorer()\n",
    "        ],\n",
    "        queries,\n",
    "        qrels,\n",
    "        [\"map\", \"ndcg_cut_10\", \"recip_rank\", \"mrt\"],\n",
    "        [\"BM25\", \"BM25_RM3_COLBERT\", \"BM25_RM3_ANCE\", \"BM25_COLBERT_RM3\", \"BM25_COLBERT_ANCE\", \"BM25_ANCE_RM3\", \"BM25_ANCE_COLBERT\"],\n",
    "        save_dir=\"vaswani-threefold\",\n",
    "        save_mode=\"reuse\",\n",
    "        baseline=0,\n",
    "        correction=\"bonferroni\"\n",
    "    )\n",
    "    threefold_results.to_csv(\"vaswani-threefold/results.csv\", sep=',', na_rep=\"NaN\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9afb9692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:01,  1.35s/it]\n",
      "Inferencing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 727it [23:47,  1.96s/it]\n",
      "c:\\Users\\Konstantin-Asen\\Desktop\\IR-research-project\\.venv\\Lib\\site-packages\\colbert\\utils\\amp.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else nullcontext()\n",
      "Inferencing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:01,  1.59s/it]\n",
      "Inferencing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 727it [23:46,  1.96s/it]\n",
      "c:\\Users\\Konstantin-Asen\\Desktop\\IR-research-project\\.venv\\Lib\\site-packages\\colbert\\utils\\amp.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else nullcontext()\n"
     ]
    }
   ],
   "source": [
    "# Ran for 337 minutes\n",
    "\n",
    "if not os.path.exists(\"vaswani-fourfold/results.csv\"):\n",
    "    bm25_rm3_colbert = pt.Transformer.from_df(pt.io.read_results(\"vaswani-threefold/BM25_RM3_COLBERT.res.gz\"), uniform=False)\n",
    "    bm25_rm3_ance = pt.Transformer.from_df(pt.io.read_results(\"vaswani-threefold/BM25_RM3_ANCE.res.gz\"), uniform=False)\n",
    "    bm25_colbert_rm3 = pt.Transformer.from_df(pt.io.read_results(\"vaswani-threefold/BM25_COLBERT_RM3.res.gz\"), uniform=False)\n",
    "    bm25_colbert_ance = pt.Transformer.from_df(pt.io.read_results(\"vaswani-threefold/BM25_COLBERT_ANCE.res.gz\"), uniform=False)\n",
    "    bm25_ance_rm3 = pt.Transformer.from_df(pt.io.read_results(\"vaswani-threefold/BM25_ANCE_RM3.res.gz\"), uniform=False)\n",
    "    bm25_ance_colbert = pt.Transformer.from_df(pt.io.read_results(\"vaswani-threefold/BM25_ANCE_COLBERT.res.gz\"), uniform=False)\n",
    "\n",
    "    fourfold_results = pt.Experiment(\n",
    "        [\n",
    "            bm25,\n",
    "            bm25_rm3_colbert >> pt.text.get_text(vaswani_index) >> ance_reranker,\n",
    "            bm25_rm3_ance >> pt.text.get_text(vaswani_index) >> colbert_reranker.text_scorer(),\n",
    "            bm25_colbert_rm3 >> pt.text.get_text(vaswani_index) >> ance_reranker,\n",
    "            bm25_colbert_ance >> rm3 >> bm25,\n",
    "            bm25_ance_rm3 >> pt.text.get_text(vaswani_index) >> colbert_reranker.text_scorer(),\n",
    "            bm25_ance_colbert >> rm3 >> bm25\n",
    "        ],\n",
    "        queries,\n",
    "        qrels,\n",
    "        [\"map\", \"ndcg_cut_10\", \"recip_rank\", \"mrt\"],\n",
    "        [\"BM25\", \"BM25_RM3_COLBERT_ANCE\", \"BM25_RM3_ANCE_COLBERT\", \"BM25_COLBERT_RM3_ANCE\", \"BM25_COLBERT_ANCE_RM3\", \"BM25_ANCE_RM3_COLBERT\", \"BM25_ANCE_COLBERT_RM3\"],\n",
    "        save_dir=\"vaswani-fourfold\",\n",
    "        save_mode=\"reuse\",\n",
    "        baseline=0,\n",
    "        correction=\"bonferroni\"\n",
    "    )\n",
    "    fourfold_results.to_csv(\"vaswani-fourfold/results.csv\", sep=',', na_rep=\"NaN\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
